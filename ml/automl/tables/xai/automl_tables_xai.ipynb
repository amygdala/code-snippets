{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Google Cloud’s [AutoML Tables](https://cloud.google.com/automl-tables/docs/) lets you automatically build and deploy state-of-the-art machine learning models using your own structured data. \n",
    "\n",
    "AutoML Tables now has an easier-to-use [Tables-specific Python client library](https://googleapis.dev/python/automl/latest/gapic/v1beta1/tables.html), \n",
    "as well as a new ability to **explain** online prediction results— called *local feature importance*—  which gives visibility into how the features in a specific prediction request informed the resulting prediction.\n",
    "\n",
    "In this notebook, we'll create a custom Tables model to predict duration of London bike rentals given information about local weather as well as info about the rental trip.\n",
    "We'll walk through examples of using the Tables client libraries for creating a dataset, training a custom model, deploying the model, and using it to make predictions; and show how you can programmatically request local feature importance information.\n",
    "\n",
    "We recommend running this notebook using [AI Platform Notebooks](https://cloud.google.com/ai-platform-notebooks/).\n",
    "If you want to run the notebook on [colab](https://colab.research.google.com/) (or locally), it's possible, but you'll need to do a bit more setup.  See the Appendix section of this notebook for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "\n",
    "Follow the [AutoML Tables documentation](https://cloud.google.com/automl-tables/docs/) to:\n",
    "\n",
    "- [Select or create a GCP project](https://console.cloud.google.com/cloud-resource-manager).\n",
    "- [Make sure that billing is enabled](https://cloud.google.com/billing/docs/how-to/modify-project) for your project\n",
    "- Enable the [Cloud AutoML and Storage APIs](https://console.cloud.google.com/flows/enableapi?apiid=storage-component.googleapis.com,automl.googleapis.com,storage-api.googleapis.com).\n",
    "- (Recommended) Create an [AI Platform Notebook](https://cloud.google.com/ai-platform-notebooks/) instance and upload this notebook to it.\n",
    "\n",
    "(See also the [Quickstart guide](https://cloud.google.com/automl-tables/docs/quickstart) for a getting-started walkthrough on AutoML Tables).\n",
    "\n",
    "Then, install the AutoML Python client libraries into your notebook environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U google-cloud-automl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to **restart your notebook kernel** after running the above to pick up the installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter your GCP project ID in the cell below, then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"<your-project-id>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some imports\n",
    "\n",
    "Next, import some libraries and set some variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import automl_v1beta1 as automl\n",
    "import google.cloud.automl_v1beta1.proto.data_types_pb2 as data_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "DATASET_NAME = 'bikes-weather'\n",
    "BIGQUERY_PROJECT_ID = 'aju-dev-demos'\n",
    "DATASET_ID = 'london_bikes_weather'\n",
    "TABLE_ID = 'bikes_weather'\n",
    "IMPORT_URI = 'bq://%s.%s.%s' % (BIGQUERY_PROJECT_ID, DATASET_ID, TABLE_ID)\n",
    "print(IMPORT_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'bikes_weather'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset, and import data\n",
    "\n",
    "Next, we'll define some utility functions to create a dataset, and to import data into a dataset.  The `client.import_data()` call returns an operation *future* that can be used to check for completion synchronously or asynchronously— in this case we wait synchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(client, dataset_display_name):\n",
    "    \"\"\"Create a dataset.\"\"\"\n",
    "\n",
    "    # Create a dataset with the given display name\n",
    "    dataset = client.create_dataset(dataset_display_name)\n",
    "\n",
    "    # Display the dataset information.\n",
    "    print(\"Dataset name: {}\".format(dataset.name))\n",
    "    print(\"Dataset id: {}\".format(dataset.name.split(\"/\")[-1]))\n",
    "    print(\"Dataset display name: {}\".format(dataset.display_name))\n",
    "    print(\"Dataset metadata:\")\n",
    "    print(\"\\t{}\".format(dataset.tables_dataset_metadata))\n",
    "    print(\"Dataset example count: {}\".format(dataset.example_count))\n",
    "    print(\"Dataset create time:\")\n",
    "    print(\"\\tseconds: {}\".format(dataset.create_time.seconds))\n",
    "    print(\"\\tnanos: {}\".format(dataset.create_time.nanos))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(client, dataset_display_name, path):\n",
    "    \"\"\"Import structured data.\"\"\"\n",
    " \n",
    "    response = None\n",
    "    if path.startswith('bq'):\n",
    "        response = client.import_data(\n",
    "            dataset_display_name=dataset_display_name, bigquery_input_uri=path\n",
    "        )\n",
    "    else:\n",
    "        # Get the multiple Google Cloud Storage URIs.\n",
    "        input_uris = path.split(\",\")\n",
    "        response = client.import_data(\n",
    "            dataset_display_name=dataset_display_name,\n",
    "            gcs_input_uris=input_uris\n",
    "        )\n",
    "\n",
    "    print(\"Processing import...\")\n",
    "    # synchronous check of operation status.\n",
    "    print(\"Data imported. {}\".format(response.result())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create the `client` object that we'll use for all our operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = automl.TablesClient(project=PROJECT_ID, region=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Tables *dataset*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(client, DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and then import data from the BigQuery table into the dataset. The import command will take a while to run. **Wait until it has returned** before proceeding.  You can also check import status in the [Cloud Console](https://console.cloud.google.com/automl-tables/datasets).\n",
    "\n",
    "(Note that if you run this notebook multiple times, you will get an error if you try to create multiple datasets with the same name. However, you can train multiple models against the same dataset.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data(client, DATASET_NAME, IMPORT_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the dataset schema\n",
    "\n",
    "Now we'll define utility functions to update dataset and column information.  We need these to set the dataset's *target column* (the field we'll train our model to predict) and to change the *types* of some of the columns. AutoML Tables is pretty good at inferring reasonable column types based on input, but in our case, there are some columns (like bike station IDs) that we want to treat as *Categorical* instead of *Numeric*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_column_spec(client,\n",
    "                       dataset_display_name,\n",
    "                       column_spec_display_name,\n",
    "                       type_code,\n",
    "                       nullable=None):\n",
    "    \"\"\"Update column spec.\"\"\"\n",
    "\n",
    "    response = client.update_column_spec(\n",
    "        dataset_display_name=dataset_display_name,\n",
    "        column_spec_display_name=column_spec_display_name,\n",
    "        type_code=type_code, nullable=nullable\n",
    "    )\n",
    "\n",
    "    # synchronous check of operation status.\n",
    "    print(\"Table spec updated. {}\".format(response))\n",
    "    \n",
    "def update_dataset(client,\n",
    "                   dataset_display_name,\n",
    "                   target_column_spec_name=None,\n",
    "                   time_column_spec_name=None,\n",
    "                   test_train_column_spec_name=None):\n",
    "    \"\"\"Update dataset.\"\"\"\n",
    "\n",
    "    if target_column_spec_name is not None:\n",
    "        response = client.set_target_column(\n",
    "            dataset_display_name=dataset_display_name,\n",
    "            column_spec_display_name=target_column_spec_name\n",
    "        )\n",
    "        print(\"Target column updated. {}\".format(response))\n",
    "    if time_column_spec_name is not None:\n",
    "        response = client.set_time_column(\n",
    "            dataset_display_name=dataset_display_name,\n",
    "            column_spec_display_name=time_column_spec_name\n",
    "        )\n",
    "        print(\"Time column updated. {}\".format(response))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_column_specs(client,\n",
    "                      dataset_display_name,\n",
    "                      filter_=None):\n",
    "    \"\"\"List all column specs.\"\"\"\n",
    "    result = []\n",
    "\n",
    "    # List all the table specs in the dataset by applying filter.\n",
    "    response = client.list_column_specs(\n",
    "        dataset_display_name=dataset_display_name, filter_=filter_)\n",
    "\n",
    "    print(\"List of column specs:\")\n",
    "    for column_spec in response:\n",
    "        # Display the column_spec information.\n",
    "        print(\"Column spec name: {}\".format(column_spec.name))\n",
    "        print(\"Column spec id: {}\".format(column_spec.name.split(\"/\")[-1]))\n",
    "        print(\"Column spec display name: {}\".format(column_spec.display_name))\n",
    "        print(\"Column spec data type: {}\".format(column_spec.data_type))\n",
    "\n",
    "        result.append(column_spec)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the dataset to indicate that the target column is `duration`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_dataset(client, DATASET_NAME,\n",
    "                target_column_spec_name='duration',\n",
    "#                 time_column_spec_name='ts'  # ughhhhh\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll update some of the column types.  You can list their default specs first if you like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_column_specs(client, DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and now we'll update them to the types we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_column_spec(client, DATASET_NAME,\n",
    "                   'end_station_id',\n",
    "                    'CATEGORY')\n",
    "update_column_spec(client, DATASET_NAME,\n",
    "                   'start_station_id',\n",
    "                    'CATEGORY')\n",
    "update_column_spec(client, DATASET_NAME,\n",
    "                   'loc_cross',\n",
    "                   'CATEGORY')\n",
    "update_column_spec(client, DATASET_NAME,\n",
    "                   'bike_id',\n",
    "                   'CATEGORY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the results in the [Cloud Console](https://console.cloud.google.com/automl-tables/datasets). Note that useful stats are generated for each column. You can also run the `list_column_specs()` function again to see the new config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_column_specs(client, DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a custom model on the dataset\n",
    "\n",
    "Now we're ready to train a model on the dataset. We'll need to generate a unique name for the model, which we'll do by appending a timestamp, in case you want to run this notebook multiple times. The `1000` arg in the `create_model()` call specifies to budget 1 hour of training time.\n",
    "\n",
    "In the `create_model()` utility function below, we may not want to block on the result, since total job time can be multiple hours. If you want the function to block until training is complete, uncomment the last line of the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "MODEL_NAME = 'bwmodel_' + str(int(time.time()))\n",
    "print('MODEL_NAME: %s' % MODEL_NAME)\n",
    "\n",
    "def create_model(client,\n",
    "                 dataset_display_name,\n",
    "                 model_display_name,\n",
    "                 train_budget_milli_node_hours,\n",
    "                 include_column_spec_names=None,\n",
    "                 exclude_column_spec_names=None):\n",
    "    \"\"\"Create a model.\"\"\"\n",
    " \n",
    "    # Create a model with the model metadata in the region.\n",
    "    response = client.create_model(\n",
    "        model_display_name,\n",
    "        train_budget_milli_node_hours=train_budget_milli_node_hours,\n",
    "        dataset_display_name=dataset_display_name,\n",
    "        include_column_spec_names=include_column_spec_names,\n",
    "        exclude_column_spec_names=exclude_column_spec_names,\n",
    "    )\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    print(\"Training operation: {}\".format(response.operation))\n",
    "    print(\"Training operation name: {}\".format(response.operation.name))\n",
    "    # uncomment the following to block until training is finished.\n",
    "    # print(\"Training completed: {}\".format(response.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model(client, DATASET_NAME, MODEL_NAME, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the status of your training job\n",
    "\n",
    "Edit the following call to **set `OP_NAME` to the \"training operation name\"** listed in the output of `create_model()` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OP_NAME = 'YOUR TRAINING OPERATION NAME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_operation_status(client, operation_full_id):\n",
    "    \"\"\"Get operation status.\"\"\"\n",
    " \n",
    "    # Get the latest state of a long-running operation.\n",
    "    op = client.auto_ml_client.transport._operations_client.get_operation(\n",
    "        operation_full_id\n",
    "    )\n",
    "\n",
    "    print(\"Operation status: {}\".format(op))\n",
    "    from google.cloud.automl import types\n",
    "    msg = types.OperationMetadata()\n",
    "    print(msg.ParseFromString(op.metadata.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training job may take several hours. You can check on its status in the Cloud Console UI. You can also monitor it via the `get_operation_status()` call below. (Make sure you've edited the OP_NAME variable value above). You'll see: `done: true` in the output when it's finished.\n",
    "\n",
    "(Note: if you should lose your notebook kernel context while the training job is running, you can continue the rest of the notebook later with a new kernel: just make note of the `MODEL_NAME`. You can find that information in the Cloud Console as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_operation_status(client, OP_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get information about your trained custom model\n",
    "\n",
    "Once it has been created, you can get information about a specific model. (While the training job is still running, you'll just get a `not found` message.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.automl_v1beta1 import enums\n",
    "from google.api_core import exceptions\n",
    "\n",
    "def get_model(client, model_display_name):\n",
    "    \"\"\"Get model details.\"\"\"\n",
    "\n",
    "    try:\n",
    "        model = client.get_model(model_display_name=model_display_name)\n",
    "    except exceptions.NotFound:\n",
    "        print(\"Model %s not found.\" % model_display_name)\n",
    "        return (None, None)\n",
    "\n",
    "    # Get complete detail of the model.a\n",
    "    model = client.get_model(model_display_name=model_display_name)\n",
    "\n",
    "    # Retrieve deployment state.\n",
    "    if model.deployment_state == enums.Model.DeploymentState.DEPLOYED:\n",
    "        deployment_state = \"deployed\"\n",
    "    else:\n",
    "        deployment_state = \"undeployed\"\n",
    "\n",
    "    # get features of top global importance\n",
    "    feat_list = [\n",
    "        (column.feature_importance, column.column_display_name)\n",
    "        for column in model.tables_model_metadata.tables_model_column_info\n",
    "    ]\n",
    "    feat_list.sort(reverse=True)\n",
    "    if len(feat_list) < 10:\n",
    "        feat_to_show = len(feat_list)\n",
    "    else:\n",
    "        feat_to_show = 10\n",
    "\n",
    "    # Display the model information.\n",
    "    print(\"Model name: {}\".format(model.name))\n",
    "    print(\"Model id: {}\".format(model.name.split(\"/\")[-1]))\n",
    "    print(\"Model display name: {}\".format(model.display_name))\n",
    "    print(\"Features of top importance:\")\n",
    "    for feat in feat_list[:feat_to_show]:\n",
    "        print(feat)\n",
    "    print(\"Model create time:\")\n",
    "    print(\"\\tseconds: {}\".format(model.create_time.seconds))\n",
    "    print(\"\\tnanos: {}\".format(model.create_time.nanos))\n",
    "    print(\"Model deployment state: {}\".format(deployment_state))\n",
    "\n",
    "    return (model, feat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Don't proceed with the rest of the notebook until the model has finished training** and the following `get_model()` call returns model information rather than '`not found`'.\n",
    "\n",
    "Once the training job has finished, we can get information about the model, including information about which input features proved to be the most **important globally** (that is, across the full training dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(model, global_feat_importance) = get_model(client, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can graph the global feature importance values to get a visualization of which inputs were most important in training the model. (The Cloud Console UI also displays such a graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(global_feat_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "res = list(zip(*global_feat_importance))\n",
    "x = list(res[0])\n",
    "y = list(res[1])\n",
    "\n",
    "y_pos = list(range(len(y)))\n",
    "plt.barh(y_pos, x, alpha=0.5)\n",
    "plt.yticks(y_pos, y)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See your model's evaluation metrics\n",
    "\n",
    "We can also get model evaluation information once the model is trained.  The available metrics depend upon which optimization objective you used.  In this example, we used the default, **RMSE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = client.list_model_evaluations(model_display_name=MODEL_NAME)\n",
    "list(evals)[1].regression_evaluation_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use your trained model to make predictions and see explanations of the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy your model and get predictions + explanations\n",
    "\n",
    "Once your training job has finished, you can use your model to make predictions.  \n",
    "\n",
    "With *online prediction*, you can now request **explanations** of the results, in the form of **[local feature importance](https://cloud.google.com/automl-tables/docs/features#feat-imp)** calculations on the inputs. Local feature importance gives you visibility into how the features in a specific prediction request informed the resulting prediction.\n",
    "\n",
    "To get online predictions, we first need to **deploy** the model.\n",
    "\n",
    "Note: see the [documentation](https://cloud.google.com/automl-tables/docs/) for other prediction options including the ability to [export](link_to_blog_post) your custom model and run it in a container anywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deploy_model(client, model_display_name):\n",
    "    \"\"\"Deploy model.\"\"\"\n",
    "\n",
    "    response = client.deploy_model(model_display_name=model_display_name)\n",
    "    # synchronous check of operation status.\n",
    "    print(\"Model deployed. {}\".format(response.result()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will take a while to deploy the model. **Wait for the `deploy_model()` call to finish** before proceeding with the rest of the notebook cells. You can track status in the Console UI as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_model(client, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is deployed, you can access it via the UI, or the API, to make online prediction requests.  These can include a request for [local feature importance](https://cloud.google.com/automl-tables/docs/features#feat-imp) calculations on the inputs, a newly-launched feature. Local feature importance gives you visibility into how the features in a specific prediction request informed the resulting prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(client,\n",
    "            model_display_name,\n",
    "            inputs,\n",
    "            feature_importance=False):\n",
    "    \"\"\"Make a prediction.\"\"\"\n",
    "\n",
    "    if feature_importance:\n",
    "        response = client.predict(\n",
    "            model_display_name=model_display_name,\n",
    "            inputs=inputs,\n",
    "            feature_importance=True,\n",
    "        )\n",
    "    else:\n",
    "        response = client.predict(\n",
    "            model_display_name=model_display_name,\n",
    "            inputs=inputs)\n",
    "    print(\"Prediction results:\")\n",
    "    print(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs =  {\n",
    "      \"bike_id\": \"5373\",\n",
    "      \"day_of_week\": \"3\",\n",
    "      \"end_latitude\": 51.52059681,\n",
    "      \"end_longitude\": -0.116688468,\n",
    "      \"end_station_id\": \"68\",\n",
    "      \"euclidean\": 3589.5146210024977,\n",
    "      \"loc_cross\": \"POINT(-0.07 51.52)POINT(-0.12 51.52)\",\n",
    "      \"max\": 44.6,\n",
    "      \"min\": 34.0,\n",
    "      \"prcp\": 0,\n",
    "      \"ts\": \"1480407420\",\n",
    "      \"start_latitude\": 51.52388,\n",
    "      \"start_longitude\": -0.065076,\n",
    "      \"start_station_id\": \"445\",\n",
    "      \"temp\": 38.2,\n",
    "      \"dewp\": 28.6\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try running the prediction request first without, then with, the local feature importance calculations, to see the difference in the information that is returned. (The actual duration— that we're predicting— is 1200.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(client, MODEL_NAME, inputs, feature_importance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = predict(client, MODEL_NAME, inputs, feature_importance=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the local feature importance values to get a visualization of which fields were most and least important for this particular prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "col_info = response.payload[0].tables.tables_model_column_info\n",
    "x = []\n",
    "y = []\n",
    "for c in col_info:\n",
    "  y.append(c.column_display_name)\n",
    "  x.append(c.feature_importance)\n",
    "y_pos = list(range(len(y)))\n",
    "plt.barh(y_pos, x, alpha=0.5)\n",
    "plt.yticks(y_pos, y)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see a similar graphic in the [Cloud Console Tables UI](https://pantheon.corp.google.com/automl-tables/) when you submit an `ONLINE PREDICTION` and tick the \"Generate feature importance\" checkbox.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The local feature importance calculations are specific to a given input instance.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we showed how you can use the AutoML Tables client library to create datasets, train models, and get predictions from your trained model— and in particular, how you can get explanations of the results along with the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: running this notebook on colab (or locally)\n",
    "\n",
    "It's possible to run this example on [colab](https://colab.research.google.com/), but it takes a bit more setup. Do the following before you create the Tables client object or call the API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Create a service account](https://cloud.google.com/iam/docs/creating-managing-service-accounts), give it the necessary *roles* (e.g., AutoML Admin) and [download a json credentials file](https://cloud.google.com/iam/docs/creating-managing-service-account-keys) for the service account.  **Upload** the credentials file to the colab file system. \n",
    "\n",
    "Then, **edit** the following to point to that file, and run the cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env GOOGLE_APPLICATION_CREDENTIALS /content/your-credentials-file.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Tables API calls should now be properly authenticated.  If you lose the colab runtime, you'll need to re-upload the file and re-set the environment variable.\n",
    "\n",
    "If you're running the notebook locally, point the `GOOGLE_APPLICATION_CREDENTIALS` environment variable to the service account credentials file before starting the notebook, e.g.:\n",
    "\n",
    "```sh\n",
    "export GOOGLE_APPLICATION_CREDENTIALS=/path/to/your-credentials-file.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "Copyright 2019 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
